Title?

PCP^3: A C Front End for Preprocessor Analysis and Transformation

Date: Thursday, Oct 23, 1997, 10am, Sieg 422
Practice: Tuesday Oct. 21, 1997, 11:30am, Sieg 422
Paper: Thursday, October 16, 1997

* Abstract

* Introduction

** CPP stinks -- Stroustrup quote (slide: e.g. of impossible semantics)
*** exposes less to compiler proper, harder for tools to parse source, huge chasm between what s.e. and compiler sees
*** Ideally, we'd like to remove use of cpp
*** newer language features are one possible route to this end, with many benefits
**** exposes syms to debugger,
**** increases potential for compiler optimization
**** improved tools, program understanding
**** higher level of abstraction
**** less "dead code" unseen by the compiler, easier to maintain

** Lots of CPP uses can be expressed in C++ language
*** simple examples
**** #define-s of constants
**** conditional compilation of debug code
***** C programmers overly concerned w/ efficiency; issue is confidence in compiler doing dce, they have confidence in cpp doing it because of its primitive mechanism
**** BUT: #include still necessary, some uses of conditional compilation directives really hard, complicated macros using stringization/pasting, etc.
*** Authors recommend this; Stroustrup, Carrol and Ellis

** But what about Legacy code?

* Background

** Empirical analysis to see how bad it is
*** lots of cpp use is really simple and doesn't step outside of things doable in C++ language proper
*** BUT, the difficult (evil) uses are the ones that are hard to replace w/i the language;  those are the ones causing the most problems (esp. for tools) [one solution here is to expand such uses out]

** Automatic/automated transformation is possible
*** basically just source->source transformation tool, BUT both source languages are hindered by CPP
*** Other tools have used three approaches:
**** work on postprocessed code
**** ignore cpp
**** do approx job trying to handle cpp and the C language itself (em_tools approach)
*** Only the third approach is workable in the context of trying to deal w/ cpp

** New approach, tightly couple cpp and parser and let them work together
*** Real cpp (cpplib) from GCC
*** Tested, supported parser which builds an AST from CTree (attempt to avoid reliance on it, though)
*** Perl hooks for various preprocessing and parsing "events"
**** potential for reuse of em_tools code
**** higher level language nice for experimenting, lots of libraries
*** Uses compilation paradigm, not entire package scanning like em_tools
**** provides necessary conservative analysis required when you want to transform
**** analysis can vary for a given file in the context of prior defines before inclusion
***** Stroustrup thinks this should be disallowed, but fairly common technique
**** handling multiple translation units

* Infrastructure of PCP^3: Parser integrated with CPP and Perl
** more fine-grained mapping
** more than just a thin straw funnelling tokens between levels of analysis, better interaction and data sharing
** flexible, general framework w/ possibilities for extension
** useful for prg understanding, too
** more global reasoning is possible, since you don't have to ignore lines conditionally-compiled out
** reuse of existing tested components
*** confidence that cpp level and parse level are doing the right thing
*** approach extends to applying directly to a compiler, possible by gcc guru but not me
** hooks infrastructure (37 hooks, 25 backcalls)
*** think about how to handle various constructs, don't worry about main loop
** Annotate code at character level + provide viewer in Emacs
*** leverage existing editing tool
*** ASTs are not ready for prime-time editing, lots of HCI issues
*** ASTs would necessarily not be as clean to cope with some cpp constructs
*** integrate understanding and transformation;  text is a good universal medium
** multiple translation units -- how handled -- textual annotations this is easy

* Results
** Program understanding in light of preprocessor directives
*** postprocessed code markup
*** source code annotation
*** Def/Use for Macros
** Simple transformation of #define-s of constants
*** Not so hard
*** Not so simple
**** naming conventions, change macro invokations
**** multiple translation units; multiple definitions; nested expansions; scope; where does decl go
**** use enum vs. const?
*** Partial solution -- the standard one: be conservative!
**** also provide s.e. w/ analysis capabilities to make informed decisions
**** flexibility of framework is essential since set of possibile analyses is huge
** Example transformation
** Performance

* Shortcomings of PCP^3
** Integrating cpplib and ctree parser with perl not easy
*** obtuse code
*** two parsers, perl's + ctree's (ironic: use of preprocessor helped a great deal due to lack of namespaces in C)
** Fairly dependent on internals of the preprocessing and parsing peculiarities of the tools
** Huge effort in making the hooks interface complete; existing hooks motivated by need not by design
** Also data structure sharing; duplication of work between perl code and cpp/parser structures
** AST going to waste for now

* Related work
** Tawk
** ASTLog
** TXL
** Krone & Snelting

* Summary and Future work
* Other/Possible applications
** Syntax highlighting
** Source + output annotations
** Tags generation
*** lexical approximation tools have had years to evolve & work great, esp. on, e.g., Emacs soure, since crazy constructs in the code resulting in mis-pseudo-parses of code that matters is likely considered a bug in the tool and would result in a hack bug-fix to the tool to make it get it right in the important case;  years of iteration make them accurate.
** Call graph extraction (add summaries to fns)
** parser debugging, teaching
** multi-version reasoning

* Acknowledgements

* Appendix A: Hooks (C calling perl)

* Appendix B: Backcalls (perl calling C)

* References
