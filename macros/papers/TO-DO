> What criteria did you use to prune your taxonomy for this paper?  Was
> there anything useful in the elaboration of some taxons?  Did you do
> some pruning on the basis of experimental measurement?  If so, it may
> be worth saying ``a priori, we though taxon X would be significant,
> but measurements showed otherwise, so we consider X only as it forms
> part of Y.''

> (Aside: I suspect that a discussion of the taxonomy will show that it
> does not make sense to lump Makefiles and other non-C code in with the
> C programs in the experimental measurements.)

We process some files containing many macro definitions, some of which were
primarily used in C code and some of which were primarily used in Makefiles
or elsewhere.  This does occurs in practice (for instance, it may be used
for configuration), as we've made clear in the paper.


Be sure that we offer the code and the data (give a URL, or not?).


> You have version numbers.  Do you have other
> independent information (even guesses) about the packages?  Bug rates?
> Number of users?  Can your analysis of usage within a package tell us
> anything about that package?

Though this would definitely be interesting, and we now mention it in
our new Future work section 10, it is not our intention in this paper to 
do a longitudinal study on a single package.  We expect our work will
encourage and enable careful study of other features.

> What does it mean to say cpp can define new syntax?

Cpp can create operators (macros) which differ from any pre-existing
language constructs -- say, by taking types as arguments.  The current
draft doesn't spell this out, but we can add this if desired.

[This is in the first sentence; careful about expanding too much here.]

> What does it mean to say cpp permits system dependencies to be made
> explicit and tested?

An explicit #if is superior to, say, instructions in a README file about
different ways to build a program on different platforms.  The Cpp macros
and tests reify those system dependences.  Again, this is not included in
the current draft but can easily be added if necessary.

[This is in the first paragraph; careful about expanding too much here.]

> What is `disciplined' use of the preprocessor?  Who decides?  Which of
> the usages in the paper are disciplined?  Connect the usages with
> programmer effort and portability.

Disciplined use avoids error-prone and difficult-to-understand constructs.
The remainder of the paper investigates which constructs those are.  They
will depend to some extent on specific circumstances and needs and as such
are difficult to formalize.

> I'm not very convinced by your list.  It's all
> too vague and general.  Try to improve or prune the list.  Definitely
> give a concrete example of each.

We give an example of each, with each example taken directly from one of
the packages we studied.
[Do we say that explicitly?]

> Why is high total use problematic?  Computers are good at doing
> the same thing over and over.

People are not, however; the text refers to humans as well as tools.
More directly to the point, one might hypothesize that the approach chosen
by most tools -- to ignore macros -- would work well if there are few
macros.  (The problems with such approaches -- for instance, the tool
reports errors if the tool tries to treat macros as variables or functions,
or discrepancies between the tool's input and the actual source code if the
code is preprocessed before being analyzed by the tool -- are discussed
immediately above.  A small amount of such problems might be acceptable to
a user; a large amount is likely not to.)  The quantity of preprocessor use
is directly relevant to that hypothesis.

> Some of the value of macros comes from multiple definitions (e.g., for
> portability or dialects).  Why is this a problem?  Make your case.

The problem, as now noted in the text, is when the definitions are
incompatible.  They apparently have different intended uses, and such name
clashes can lead to either bugs or difficulties in understanding the code.



>   3) There are almost no small programs.

Right!  That's a feature.  Small programs are amenable to hand-analysis or
to ad hoc techniques.  A small program can be successfully written in
almost any style and can be successfully analyzed by almost any technique,
including manual ones.  Since small programs may have different properties
than large programs -- which are the only ones that are hard to deal with,
so are of most interest to researchers and practitioners -- we have omitted
them.

>   4) Interesting codes possibly worth adding include:
>        - the Linux kernel or parts thereof
>        - BSD sources
>        - Runtime system from SML/NJ or Objective CAML
>        - tcl implementation
>        - Hanson's C Interfaces and Implementations

These are good suggestions; we had many other candidates as well.  With
well over a million lines of code already under analysis, we decided that
we didn't need any more programs.  Additionally, we did not wish to
introduce even further variation into our population (say, by including
partial programs or libraries).

> I found I didn't learn anything from the fact that different packages
> had different profiles.  I was disappointed.  Did you learn anything?

One might speculate that all packages use Cpp in similar ways.  We have
disproved that speculation.  In the absence of our data, one might further
speculate that a tool could focus on just a few Cpp directives, ignoring
the others that are little used, and yet handle the majority of Cpp usage.
Our data also disproves that speculation.  This is now explained in the last
sentence of the introduction to section 4.

Additionally, it seems valuable to provide the data, as others might notice
patterns that we did not.  Finally, we address the packages making most use
of Cpp in section 4.2.

> How much of your 11,000 lines of perl might be useful for other kinds
> of analyses?

It depends on the analysis; anywhere from nearly all of it it nearly none
of it, we would guess.  Much of the code is an approximate, Cpp-aware
parser that others might find useful.  Reuse of our infrastructure for
other kinds of analyses was not a primary driver during our research.

> HAVE_PROTO is worth discussing.  You may want to compare the
> HAVE_PROTO technique to this technique:
>   #ifdef __STDC__
>   #define ARGS(list) list
>   #else
>   #define ARGS(list) ()
>   #endif
> and its use as
>   extern void  *allocate ARGS((unsigned long n, unsigned a));
> in order to make the point that it is not necessary to have so much
> conditional compilation.

Such an approach has the (often unacceptable) consequence of omitting type
information from the declaration in the K&R case.  Some packages use a more
convoluted style to achieve the proper effect, like this example from bc
(files bc-1.03/dc.h and bc-1.03/dc-number.c):

  #ifndef __STDC__
  # define DC_PROTO(x)			()
  # define DC_DECLVOID()			()
  # define DC_DECLARG(arglist)	arglist
  # define DC_DECLSEP				;
  # define DC_DECLEND				;
  #else /* __STDC__ */
  # define DC_PROTO(x)			x
  # define DC_DECLVOID()			(void)
  # define DC_DECLARG(arglist)	(
  # define DC_DECLSEP				,
  # define DC_DECLEND				)
  #endif /* __STDC__ */

  dc_data
  dc_getnum DC_DECLARG((input, ibase, readahead))
	  int (*input) DC_PROTO((void)) DC_DECLSEP
	  int ibase DC_DECLSEP
	  int *readahead DC_DECLEND
  {
    /* function body */
  }

It is hard to argue that this is really superior to the HAVE_PROTO case,
for which at least some tools (such as tags tables and approximate parsers)
work.  We had omitted a discussion of this because of length, but can
reinstate it if necessary.

> Shouldn't the extra-linguistic category include Syntactic macros?

The third sentence of the paragraph notes that extra-linguistic
capabilities provide a feature unavailable in the C language.  By contrast,
macros categorized as syntactic act as punctuation.  Since these are
orthogonal classifications, some but not all syntactic macros will provide
extra-linguistic capabilities (such as dynamic binding).
[This is in sec:extra-linguistic.]

> How did you develop your list of macro pitfalls?  Aren't these
> well known in the C literature?  How does your work relate?
> Your contribution would be more valuable if you were identifying the
> incidence of well understood problems instead of problems of your own
> invention. 

Our list comes primarily from our own experience and examination of our
codebase; after developing it, we formally compared it to the lists of
others, as described in Section 8.  (We did that comparison last to avoid
being prejudiced by others' results.  We were not completely uninfluenced
by previous work, as some of the errors are well-known in the C/C++
community and in many cases we had previously read those papers or
manuals.)

We have found no other list as comprehensive as ours, though most of the
items appear on some other list of macro errors or recommendations.
(Exceptions include free non-global variables (a potential, not certain,
error), inconsistent arity, and null body with arguments.)

All of our examples come from the packages we studied, and we culled our
list by eliminating warnings we considered uninteresting or which did not
appear in practice.


Not all macros look like function calls; in particular, argumentless macros
do not.  


This is an example of a fact that has startled some readers while coming as
no surprise to other readers with a different background.  Empirically, we
have found it impossible to predict what will be interesting or boring to
different audiences; as we note in our cover letter, responses have been
quite varied.


> In Section 6.1, are we talking multiple macros on one line or macros
> invoking macros?  Wouldn't it be useful to distinguish those cases?

This section is about dependences, which include invocations (which we call
expansion-dependence) but are not restricted to them.  Our data give
transitive dependences.  We hope this is now clear from our remark that the
LEGITIMIZE_ADDRESS line, which contains five tokens (and only one macro) is
dependent on hundreds of macros.

> If so, how frequent are
> those usages according to your data?  Does the frequency vary by
> package?

We collected this data, but do not have room for it in the paper (and did
not find it particularly illuminating).

> Can the variation be correlated to maturity?  Bug reports?
> Age relative to the ANSI standard?

As mentioned earlier, a detailed study of specific software packages would
be welcome but is beyond the scope of this paper.

> Page 27:
> 
> Define `problematic' uses.

Uses are problematic if they are likely to inhibit some task, such as
correct execution, program understanding, or automatic analysis.  In
particular, erroneous macros and those that expand as a sequence of tokens
rather than a whole language construct fall under this rubric; others may,
too, depending on the context.

We have eliminated many uses of this word, often substituting
"error-prone", but that does not capture the full connotations of
"problematic", which we often desire.

> How are the good practices in section 8 different from recommendations
> made by others?  The benefits you list are very abstract.  Make a case
> for concrete benefits; show the real problems that are created by
> ``problematic'' macros.

Section 5.3 shows specific problems caused by erroneous macros.  Other
problems are often too lengthy for a concrete example.  Our arguments about
understandability and ease of programming would require a very substantial
study and then would still be open to doubt; many experienced programmers
have found them persuasive in their current form.

We also expanded this section to add more references to others' lists; some
of those lists are also detailed in the previous section.

> You claim to have found interesting and surprising features.  I'm not
> convinced---identify the most important such features.

Importance depends crucially on task, and surprise, too, depends on the
reader's preconceptions, prejudices, and previous experience.  Also see
point 10 of our cover letter.

[Say this explicitly.]

===========================================================================

The revision, while much improved, is still flawed.  I have found it
difficult to make a recommendation.  While I believe this paper is not
suitable for publication in its current form, I also believe in the
value of the work.  TSE rules do not permit me to recommend another
major revision, so my only possible recommendations are rejection, or
acceptance with minor revisions to be handled by the editor.  With
grave reservations, I have recommended the latter.

The major problem with the paper is that it does not deliver on its
claims.  It does not produce `an understanding of actual usage.'  It
does not `provides significant insights' about how the preprocessor is
used in practice.  It does not `confirm or contradict intuitions'
about the preprocessor.  The paper presents data, not insights.
Accordingly, if the paper is to be published, the introduction and
abstract *must* be revised to withdraw the first two claims.  Your
revised introduction should include all of the information and caveats
that appear in items 10 and 11 of the letter that accompanies your
revision.  I believe you may be able substantiate the third claim,
which you make in the conclusion; otherwise, it too must go.
[Add some explanation of some sort here.]

Another serious problem is that you still do not present sufficient
evidence or reasoning indicating why some macros are `erroneous' or
`problematic'.  Too often these claims are bald assertions.

The taxonomy in section 5.3 contains two grave errors in judgment (in my
opinion) and an error of fact.  For the paper to be acceptable, this
section *must* include the *reasoning* backing up the claims.  More below.

The conclusions are much too sketchy.  For example, I can't even
identify which uses are common for purposes of writing programming
tools.  If you haven't actually identified common uses, but expect me
to pull them out of your data, you expect too much.  If you have
identified common uses, share your knowledge.  As another example,
*which* features were interesting and surprising?  Which results were
not predictable a priori.

There are areas of presentation, particularly of figures, that still
warrant substantial improvement.  Figure 10 in particular is
unacceptable.  You have most of the information from my first review.


Details follow.


What are the `difficulties' that could be caused at the end of the
penultimate paragraph of your introduction?  I had thought section 2
would make these clear, but it does not.  Section 2 contains only
constructs that are asserted `problematic' without supporting evidence
(another problem that should have been fixed in this revision).

At the top of page 3, identify situations in which `only some sort of
preprocessing of Cpp analysis can produce useful answers'.

I'm alarmed that the Statement category on page 8 doesn't distinguish
the else-capturing FREE from the other macros, nor the SIGNAL_RETURN,
which requires a semicolon, from the SWALLOW_LINE, which may behave
strangely when followed by semicolon 
(e.g., if (p) SWALLOW_LINE(fp); else assert(feof(fp));)
[Give examples of all 6.  Make clear that we kept them separate in our
analyses, but merged them for presentation.]

Even the Symbol and Unknown Symbol categories deserve examples.
[Do this.]

I still learn nothing from Figure 4.  Put it in an appendix, or better
yet, make the data available electronically.


You present no evidence for the `more unexpected and harder to
understand' claim at the top of page 12.




Page 14, `side-effected formal' appears wrong.  Neither glyphs nor
frame need be an lvalue.  I agree that frame must be the name of a
field in a struct pointed to by glyphs, and this is passing strange.
Consider, e.g.,
  #define SET_GLYPHS_FRAME(glyphs,frame) (set_ ## #frame((glyphs), (frame)))
as an alternative.  Might not this simple function call serve as well?
Or am I overlooking something obvious?
[This criticism is right; choose another example from this category.]


In section 5.5, I am surprised by the decision to consider all strings
and character literals identical.  What happens if this element of the
canonicalization isn't done?  Do the results change in any interesting
way?  (If this was in the first draft, my apologies for missing it
then.)


In your conclusions, you claim your article `serves to confirm or
contradict intuitions about the use of the C preprocessor'.  This is
an important claim and again unsubstantiated.  Please give us a good
selection of intuitions and show how the information you have gathered
serves to confirm or contradict them.
[This would be nice to do, if possible.  But is it reasonable to do
comprehensively in the time alotted?]

"type" vs "type related" for a category (see figs 8, 6; they are not
consistent).

END OF MESSAGE

===========================================================================

Greg:


Please explain the huge Unknown Symbol entry for perl.
[Do this.] 
 -- EXPLANATION FOLLOWS:
embed.h contains 1058 lines like:
  #define Sv              Perl_Sv
  #define Xpv             Perl_Xpv
to protect global symbols from name conflicts.  It's just a renaming technique,
but all of the Perl_ symbols aren't used anywhere else in the library, because
the code uses just Sv, e.g.;  embed.h's job is to prevent that symbol from
being globally visible in the object file, but instead put Perl_Sv in its place.

Note that embed.h is an automatically-generated file, created by
embed.pl from global.sym and interp.sym.



How did you classify the names (symbols) mentioned at the top of page
23?

"SYMBOL" -> "IDENTIFIER" in figures and text 
  --done [edited *.tex, postscript] 01/15/00 gjb

I would love to see a Tukey box (median, mean, quartiles, and 90%
confidence) added to figure 9 as a summary row.
[Do this, probably.]
  -- not available in Excel 97/2000, so probably not worth it.

Get tar file for all the raw data 
  --done [but just tgz files of pkgs] 01/15/00 gjb

Figure 10:
  You should put a break in your X axis as well, and if
possibly insert the usual wavy symbol for `large gap'.
[Do add the gap and wavy line.]  
  --done [edited postscript] 01/15/00 gjb
