%$Id$
%evil.bib

@string{ph = {Prentice-Hall}}
@string{ph:adr = "Englewood Cliffs, New Jersey"}
@string{aw = "Addison-Wesley"}
@string{aw:adr = "Reading, Massachusetts"}
@string{uw = {University of Washington}}
@string{uw:adr = {Seattle, Washington}}

@string{PARC = "Xerox Palo Alto Research Center"}

@string{fse94="Proceedings of SIGSOFT '94 Second ACM SIGSOFT Symposium
on the Foundations of Software Engineering"} 

@string{fse95="Proceedings of SIGSOFT '95 Third ACM SIGSOFT Symposium
on the Foundations of Software Engineering"} 

@string{fse96="Proceedings of SIGSOFT '96 Fourth ACM SIGSOFT Symposium
on the Foundations of Software Engineering"} 

@string{icse18 = "Proceedings of the 18th International Conference on
Software Engineering"}

@string{ICSE94 = "Proceedings of the 16th International Conference on
                 Software Engineering"}

@string{icse97 = "Proceedings of the 1997 International Conference on
Software Engineering"}
@string{icse99 = "Proceedings of the 1999 International Conference on
Software Engineering"}


@TechReport{ellemtel92,
  author = 	 {{Ellemtel Telecommunication Systems Laboratory}},
  title = 	 {Programming in {C++}: Rules and Recommendations},
  institution =  {Ellemtel Telecommunications},
  year = 	 1992,
  address =	 {Sweden}
}


Update according to GCC manual?
@Manual{cpp-manual,
  title = 	 {{GNU} {C} Preprocessor Manual},
  author =	 {{GNU~P}roject},
  edition =	 {v2.7.2}
}

@Manual{GCC,
  title = 	 "Using and Porting {GNU} {CC}",
  author = 	 "Richard M. Stallman",
  organization = "Free Software Foundation",
  address = 	 "Boston, MA, USA",
  edition = 	 "2.7.2",
  year = 	 1996,
  month = 	 jun # "~29,",
}

@Manual{Stallman97,
  title = 	 {{GNU} Coding Standards},
  author =	 {Richard Stallman},
  organization = {{GNU} Project},
  year =	 1997,
  month =	 {July},
  note =	 {\relax{}ftp://prep.ai.mit.edu/\discretionary{}{}{}pub/\discretionary{}{}{}gnu/\discretionary{}{}{}standards/\discretionary{}{}{}standards.texi}
}
The use of "\relax{}" in the note prevents BibTeX from making a bad break
(in the middle of a TeX \discretionary macro).  Don't change!


@Misc{Deutsch90,
  author =	 {Deutsch, Peter},
  title =	 {ansi2knr},
  howpublished = {Freely available software program},
  year =	 1990,
  month =	 {December},
  note =	 {Included in the ghostscript distribution from Aladdin Enterprises}
}


@Manual{Cannon95,
  title = 	 {Recommended {C} Style and Coding Standards},
  author =	 {Cannon, L.W. and Elliott, R.A. and Kirchoff, L.W. and Miller, J.H. and Mitze, R.W. and Schan, E.P. and Whittington, N.O. and Spencer, Henry and Keppel, David and Brader, Mark},
  edition =	 {6.0},
  year =	 1995,
  month =	 {14 February}
}

@Manual{Dolenc90,
  title = 	 {Notes on Writing Portable Programs in {C}},
  author =	 {Dolenc, A. and Keppel, D. and Reilly, G. V.},
  edition =	 {8th Revision},
  year =	 1990,
  month =	 {November},
  note =         {\relax{}http://www.apocalypse.org/\discretionary{}{}{}pub/\discretionary{}{}{}u/\discretionary{}{}{}paul/\discretionary{}{}{}docs/\discretionary{}{}{}cport/\discretionary{}{}{}cport.htm}
}

@InProceedings( Murphy-icse18,
  author= 	"Murphy, Gail C. and Notkin, David and Lan, Erica S.-C.",
  title= 	"{An empirical study of static call graph extractors}",
  booktitle= 	icse18,
  pages= 	"90--99",
  month= 	mar,
  year= 	1996
)

@book( Stroustrup-DesignEvolution,
  author=       "Stroustrup, Bjarne",
  title=        "The Design and Evolution of {C++}",
  publisher=    aw,
  address =	aw:adr,
  year=         1994
)

@InProceedings( Siff-fse96,
  author= 	"Siff, Michael and Reps, Thomas",
  title= 	"Program generalization for software reuse: From {C} to {C++}",
  booktitle= 	FSE96,
  pages= 	"135--146",
  month= 	oct,
  year= 	1996
)

@InProceedings( OCallahan-icse97,
  author= 	"O'Callahan, Robert and Jackson, Daniel",
  title= 	"{Lackwit}: A program understanding tool based on type 
                inference",
  booktitle= 	icse97,
  month= 	may,
  year= 	1997,
  pages =        "338--348",
  publisher =    "ACM Press",
)

@Book{KernighanR88,
  author = 	 "Kernighan, Brian W. and Ritchie, Dennis M.",
  title = 	 "The {C} Programming Language",
  publisher = 	 ph,
  year = 	 1988,
  address =	 ph:adr,
  edition =	 "Second"
}

@Book{Carroll95,
  author = 	 {Carroll, Martin D. and Ellis, Margaret A.},
  title = 	 "Designing and Coding Reusable {C++}",
  publisher = 	 aw,
  address =	 aw:adr,
  year = 	 1995
}

@Book{Harbison91,
  author = 	 "Harbison, Samuel P. and Guy L. {Steele Jr.}",
  title = 	 "{C}: A Reference Manual",
  publisher = 	 ph,
  year = 	 1995,
  address =	 ph:adr,
  edition =	 "Fourth"
}

@InProceedings( Evans-fse94,
  author= 	"Evans, David and Guttag, John and Horning, Jim and Tan, Yang Meng",
  title= 	"{LCLint}: A tool for using specifications to check code",
  booktitle= 	FSE94,
  pages= 	"87--96",
  month= 	dec,
  year= 	1994
)

@Manual{Evans:LCLint,
  title = 	 {LCLint User's Guide},
  author =	 {David Evans},
  OPTorganization = {},
  OPTaddress = 	 {},
  year =	 1996,
  month =	 Aug,
  note =	 {Version 2.2.  http://larch-www.lcs.mit.edu:8001/\discretionary{}{}{}larch/\discretionary{}{}{}lclint/\discretionary{}{}{}guide/\discretionary{}{}{}guide.html}
}


@InProceedings{Krone94,
  author = 	 {Krone, Maren and Snelting, Gregor},
  title = 	 "On the Inference of Configuration Structures from Source Code",
  booktitle = 	 ICSE94,
  year =	 1994,
  publisher =	 {IEEE Computer Society Press},
  month =	 {May},
  pages =	 {49-57}
}

@TechReport{Zellweger83:TR,
  author = 	 "Polle T. Zellweger",
  title = 	 "An Interactive High-Level Debugger for Control-Flow
		  Optimized Programs",
  institution =  PARC,
  year = 	 1983,
  number =	 "CSL-83-1",
  address =	 "Palo Alto, California",
  month =	 Jan
}

@InProceedings{WeiseC93,
  author =       "Daniel Weise and Roger Crew",
  title = 	 "Programmable Syntax Macros",
  booktitle =    "ACM SIGPLAN Conference on Programming Language Design and
  	         Implementation",
  year =	 1993,
  address =	 "Albuquerque, NM",
  month =	 jun,
  pages =        "156--165"
}
PLDI93, SIGPLAN Notices 6:28


@TechReport{CppAwareCAnalyses,
  author = 	 {Badros, Greg and Notkin, David},
  title = 	 {A Framework for Preprocessor-Aware C Source Code Analyses},
  institution =  uw,
  year = 	 1998,
  number =	 {UW-CSE-98-08-04},
  address =	 uw:adr,
  month =	 {August}
}


@InProceedings{GriswoldAM96,
  author = 	 "W. G. Griswold and D. C. Atkinson and C. McCurdy",
  title = 	 "Fast, Flexible Syntactic Pattern Matching and Processing",
  booktitle = 	 "Proceedings of the IEEE 1996 Workshop on Program Comprehension",
  OPTpages = 	 "",
  year =	 1996,
  month =	 mar,
  OPTaddress = 	 "",
}
  Abstract:
"Program understanding can be assisted by tools that match patterns in the
program source. Lexical pattern matchers provide excellent performance and
ease of use, but have a limited vocabulary. Syntactic matchers provide more
precision, but may sacrifice performance, retargetability, ease of use, or
generality.
  "To achieve more of the benefits of both models, we extend the pattern
syntax of awk to support matching of abstract syntax trees, as demonstrated
in a tool called tawk. Its pattern syntax is language-independent, based on
abstract tree patterns. As in awk, patterns can have associated actions,
which in tawk are written in C for generality, familiarity, and
performance. The use of C is simplified by high-level libraries and dynamic
linking. To allow processing of program files containing non-syntactic
constructs, mechanisms have been designed that allow transparent matching
in a syntactic fashion. So far, tawk has been retargeted to the MUMPS and C
programming languages.
  "We survey and apply prototypical approaches to concretely demonstrate the
tradeoffs. Our results indicate that tawk can be used to quickly and easily
perform a variety of common software engineering tasks, and the extensions
to accommodate non-syntactic features significantly extend the generality
of syntactic matchers."
  My comments:
  I read a draft longer version (apparently word-for-word from the workshop,
but with some additions such as expanded related work).
  The goal is to provide a version of grep or awk customized for a
particular programming language:  permit programmers to easily make queries
over abstract syntax trees, not just the characters in a file.  The first
half of the paper just reviews other tools (AWK, MAWK, LSME, Scruple, A*,
Genoa) and gives examples of building call graphs from them.  The authors
conclude that matching power, flexibility, and scalability are key (see
section 4).  Their solution is TAWK, which builds an abstract syntax tree
and permits regular expressions that are based on it.  As such, it is much
more specialized to its task than are the other tools.
  For each new language, a full parser must be written (or hooked into an
existing grammar).  Actions are written in C for execution speed, and
dynamically linked for compilation/loading speed.  Users may specify on the
command line that certain symbols are typedefs.  An expert user could do a
lot with this; but after how much overhead and learning curve?
  Section 6.2 discusses macros at some length; the approach is to try
parsing the body.  If the macro body parses as a C expression or statement
(possibly sans a trailing semicolon), then leave it in the parse tree,
along with putting it in a global data structure.  (The authors state that
Scruple [Paul & Prakash 94] makes a similar suggestion for handling
macros.)  Otherwise, first try parsing assuming that each macro argument
(in turn) is a typedef; if those parses all fail, then expand the macro.
(A special version of cpp does this, and emits pragmas for type arguments
and typedefs.)  The claim is that this works for the vast majority of
macros.  This is somewhat plausible, but apparently no testing was done on
programs that support multiple dialects/languages, etc.
  The paper compares the various call graph extraction algorithms; naturally
tawk wins.  It also discusses how well macros are coped with -- only 4% to
9% of uses need to be expanded (or is that uses of 4% to 9% of macros need
to be expanded?), but this apparently doesn't include header files.  Most
of the macros that are expanded have empty bodies.
  Formatting:
Lots of confusion over "cawk" vs "tawk"; was the name recently changed?
LaTeX spacing:  "C." should be "C\<atsign>."; "\. T" should be ". T".

@Article{PaulP94,
  title =        "A framework for source code search using program
                 patterns",
  author =       "S. Paul and A. Prakash",
  journal =      "IEEE Transactions on Software Engineering",
  pages =        "463--475",
  volume =       "20",
  number =       "6",
  year =         "1994",
  note =         "It is argued that existing solutions to locating
                 source code fragments that match certain patterns are
                 insufficient. A framework in which pattern languages
                 are used to specify interesting code features is
                 presented. These are obtained by extending the source
                 programming language with pattern-matching symbols.
                 This is implemented in a tool called SCRUPLE",
  sender =       "x@wins.uva.nl",
  class =        "Reverse_Engineering, Reverse_Design,
                 Fundamental_Methods_in_Reverse_Design,
                 Source_Code_Queries",
}
The SCRUPLE tool.

Greg Minshall suggests
   Evan Adams: The Old Man and the C. USENIX Summer 1994: 15-26
I don't see the relevance and didn't get past the second page.  This is an
anecdotal, meandering account of a group of C programmers who decided to
switch their project to C++.  It describes what features they used and
which they avoided.  The audience is programmers with no knowledge of C++.


Need to add reference on CCEL.  Also CodeWizard (http://www.parasoft.com/),
which implements the tests in Scott Myers's books; but I don't see the
relevance, except that they are other kinds of lint checkers for style.


PC-Lint:
See http://www.gimpel.com, or call (610) 584-4261;  PC-Lint (runs on PCs
under NT) is $239, FlexeLint (the Unix offering) is more (they don't say
in the ad) and is distributed as shrouded source code.


@InProceedings{SpencerC92,
  author = 	 "Henry Spencer and Geoff Collyer",
  title = 	 "\#ifdef Considered Harmful, or Portability Experience with {C} {N}ews",
  booktitle = 	 "Usenix Summer 1992 Technical Conference",
  year =	 1992,
  address =	 "San Antonio, Texas",
  month =	 jun # "~8-12,",
  pages =	 "185-197",
  url = 	 "http://9www.x.bell-labs.com/user/geoff/ifdefs.ps.Z",
}
Abstract:
  We believe that a C programmer's impulse to use #ifdef in an attempt at
  portability is usually a mistake.  Portability is generally the result of
  advance planning rather than trench warfare involving #ifdef.  In the
  course of developing C News on different systems, we evolved various
  tactics for dealing with differences among systems without producing a
  welter of #ifdefs at points of difference.  We discuss alternatives to,
  and occasional proper use of, #ifdef.
While this paper talks a fair amount about #ifdef, it is more about
portability -- and even just good software engineering, such as advance
planning.  It makes strong arguments against most uses of #ifdef.  The
concluding paragraph:
  In our experience, #ifdef is usually a bad idea (though we do use it in
  places).  Its legitimate uses are fairly narrow, and it gets abused
  almost as badly as the notorious goto statement.  Like the goto, the
  #ifdef often degrades modularity and readability (intentionally or not).
  Given some advance planning, there are better ways to be portable.
The authors provide a number of principles to follow, such as
 * define a portable interface used everywhere, then provide multiple
   implementations of that interface for different systems.
 * use #ifdef only in declarations and macro definitions, never at call sites.
 * choose a standard interface, implementing it if your system's is broken
   or missing.
 * write shell scripts or use standard programs (ls, du) instead of C code
 * abolish arbitrary numeric limits; use dynamically-sized objects instead
 * choose among including separate files, rather than merging them via #ifdef
They give some statistics about C News; in 1000 lines of header files and
20,000 lines of C, they use only 166 #ifdefs.  Apparently #ifndef is
included in this count; they don't say whether #if defined(X) is included.
This isn't directly comparable to our statistics, but here's a try:
  Assume that 30% of lines are comments or code (the average over 30 packages).
  Assume that 30% of all conditional lines are #if[n]def (also the average).
  Then they have 14375 = (* (+ 19762 955) (/ 136 196.0)) NCNB lines, of which
  543 = (* 166 (/ (+ 202  6902  25844  8871  13433  4966 0.0) (+ 13433  4966)))
  are conditionals, or 3.78% = (/ 54300.0 14375).
  3.8% is under our average of 4.4%, and for a highly portable program.
They also break down the 166 uses of #ifdef into categories:
 * providing defaults (#ifndef X  #define X  default #endif)
 * commenting
 * configuration
 * multiple inclusion prevention
 * __STDC__
 * pdp11
 * lint
 * sccsid
 * STATS
 * other (just one in this category)


@TechReport{Johnson77,
  title =        "Lint, a {C} Program Checker",
  author =       "S. C. Johnson",
  type =         "Computing Science TR",
  number =       "65",
  month =        sep,
  year =         "1977",
  institution =  "Bell Labs",
  address =      "Murray Hill, NJ",
  keywords =     "CSTR",
  ignore-note =         "Updated version TM 78-1273-3",
}

@Manual{GNUEmacs19.26,
  title = 	 "{GNU} {E}macs Manual",
  author =	 "Richard Stallman",
  organization = "Free Software Foundation",
  address =	 "Cambridge, MA",
  edition =	 "Tenth",
  year =	 1994,
  month =	 Jul,
  note =	 "ISBN 1-882114-03-5"
}

@book{commonlisp:languagespec,
  title="Common Lisp: The Language",
  author="Guy L. {Steele Jr.}",
  publisher="Digital Press",
  address="Bedford, MA",
  note="Second edition",
  year=1990
}


@Article{Clinger91:R4RS,
  author =       "William Clinger and Jonathan A. Rees",
  title =        "The Revised\(^{4}\) Report on the Algorithmic Language
                 {S}cheme",
  journal =      "ACM LISP Pointers",
  volume =       "4",
  number =       "3",
  year =         "1991",
}


@Article{KelseyCR98,
  title = 	 "The Revised\(^{5}\) Report on the Algorithmic Language
                 {S}cheme",
  author = 	 "Richard Kelsey and William Clinger and Jonathan A. Rees",
  journal =      "ACM SIG{\-}PLAN Notices",
  volume =       33,
  number =       9,
  pages =        "26--76",
  month =        sep,
  year =         1998,
  coden =        "SINODQ",
  ISSN =         "0362-1340",
  bibdate =      "Tue Sep 15 17:01:28 1998",
  note =         "With H. Abelson, N. I. {Adams, IV}, D. H. Bartley, G.
                 Brooks, R. K. Dybvig, D. P. Friedman, R. Halstead, C.
                 Hanson, C. T. Haynes, E. Kohlbecker, D. Oxley, K. M.
                 Pitman, G. J. Rozas, G. L. {Steele, Jr.}, G. J.
                 Sussman, and M. Wand.",
  acknowledgement = ack-nhfb,
}


@InProceedings{lfp86*151,
  author =       "Eugene Kohlbecker and Daniel P. Friedman and Matthias
                 Felleisen and Bruce Duba",
  title =        "Hygienic Macro Expansion",
  pages =        "151--181",
  ISBN =         "0-89791-200-4",
  editor =       "Richard P. Gabriel",
  booktitle =    "Proceedings of the {ACM} Conference on {LISP} and
                 Functional Programming",
  address =      "Cambridge, MA",
  month =        aug,
  year =         "1986",
}

@Book{kicz91,
  author =       "Gregor Kiczales and Jim des Rivi\`{e}res and Daniel G.
                 Bobrow",
  title =        "The Art of the Metaobject Protocol",
  publisher =    "MIT Press",
  year =         "1991",
  entered-by =   "Andreas Paepcke",
  keywords =     "CLOS, MOP",
  comments =     "This is the official citation for the MOP spec. It can
                 also be used as a citation for an intro to the *idea*
                 of a MOP.",
}



@InProceedings{Favre96,
  author = 	 "Jean-Marie Favre",
  title = 	 "Preprocessors from an abstract point of view",
  booktitle = 	 "International Conference on Software Maintenance (ICSM'96)",
  year =	 1996,
  publisher =	 "IEEE Computer Society Press",
  address =	 "Monterey, California",
  month =	 nov # "~4--8,"
}
Argues that Cpp leads to problems in understanding.
Introduces App, an "abstract" version of Cpp which has a more traditional
programming language syntax.  A very simple semantics can be assigned to
this (because there is no looping, etc.), then traditional analyses such as
call graph construction, control and data flow analysis, slicing, and
specialization can be performed on it.  This is implemented in the
Champollion/APP environment, though the implementation doesn't cope with
"the full lexical conventions of the C language" nor with macros that take
parameters.  [We found that 72% of macro names never take any arguments; I
don't know the figure for macro definitions offhand.]


@InProceedings{Favre95,
  author = 	 "Jean-Marie Favre",
  title = 	 "The {CPP} paradox",
  booktitle = 	 "9th European Workshop on Software Maintenance",
  year =	 1995,
  address =	 "Durham, England",
  month =	 sep # "~25--27,"
}
Not much content here.
While Cpp is much-maligned, it is also much-used:  while obsolescent, it is
useful.  Discusses uses of Cpp and a list of drawbacks (non-locality, no
semantics (only uninterpreted text), lazy evaluation, no "non-defined"
value, different view for tool and programmer.
Notes that APP will give a semantics for Cpp.
This is a precursor to Favre96, and it even shares some of the same text.
Not really worth citing.


@TechReport{SpulerS92,
  author = 	 "David A. Spuler and A. Sayed Muhammed Sajeev",
  title = 	 "Static detection of preprocessor macro errors in {C}",
  institution =  "James Cook University",
  year = 	 1992,
  number =	 "92/7",
  address =	 "Townsville, Australia",
  URL = 	 "http://www.cs.jcu.edu.au/ftp/pub/techreports/92-7.ps.gz",
}
18 pages
David Spuler: dspuler at phuket.bmc.com
Abstract:
  The preprocessor incorporated into the C language is often used to substitute
  in-line code for function calls using preprocessor macros. However, the
  semantics of macro calls are different to those for function calls and there
  are a number of common pitfalls. This paper examines the most common errors
  and presents a number of algorithms whereby the compiler can detect these
  errors at compile-time. The algorithms vary in complexity from a simple
  analysis of lexical tokens in the preprocessor to examination of the parse
  tree within the parser. Most of the algorithms have been implemented in a
  prototype C macro checker called Check.
Describes a series of errors in macro definitions or use:
 * missing braces on multiple statement macros
 * dangling else in macros containing if
 * side effects to macro calls
 * operator precedence errors
"Many" of the checks have been implemented in a tool called Check.
Except for operator precedence errors, everything is at the lexical level:
no parsing, lots of approximations (eg, suppress certain errors if any
statement-like token appears in a macro).  Unsubstantiated claims about
what extra work (parsing, etc.) is worthwhile and what isn't.  Much of the
paper discusses precedence work:  a parse-free technique on definitions,
and a version with parsing which examines invocations to show uses which
actually trigger the problem.  No reports about running it on actual code
(except an implication that it's being used for a programming class).
[[Also see David A. Spuler, Check: A Better Checker for C, B Sc (Honours)
Thesis, James Cook Universaity, Townsville, Australia (1990).]]


@Unpublished{Lindig98:dagstuhl,
  author = 	 "Christian Lindig",
  title = 	 "Analysis of Software Variants",
  note = 	 "Talk at  Schloss Dagstuhl Seminar on Program Comprehension and Software Reengineering",
  year =	 1998,
  month =	 mar # "~9--13"
}
Christian Lindig <lindig at ips.cs.tu-bs.de> gave a talk at Dagstuhl regarding
analysis of software variants; the slides are
  http://www.cs.tu-bs.de/softech/papers/#Papers
  ftp://ftp.ips.cs.tu-bs.de/pub/local/softech/papers/lindig-dagstuhl-slides.ps.gz
This is a use of concept analysis to analyze C preprocessor (Cpp)
conditionals (#if), similar to Krone and Snelting.
  Lindig suggests that this can be used to find redundant concepts:  either
two conditions appear at an identical node of the lattice (those conditions
control the same lines) or a node is and-reducible (is exactly the
intersection of two other concepts/lattice nodes).  These redundant
conditions can be removed if desired.
A concept analysis tool written in C is available, but no empirical
evaluation has been performed yet.
  The full paper (in German) is lindig/98/tr-98-04.


@TechReport{lindig/98/tr-98-04,
  author =       "Christian Lindig",
  title =        "Analyse von Softwarevarianten",
  institution =  "TU Braunschweig, Institut f{\"u}r Programmiersprachen
                 und Informationssysteme, Abt. Softwaretechnologie",
  year =         "1998",
  type =         "Informatik-Bericht",
  number =       "98-04",
  address =      "D-38106 Braunschweig",
  month =        jan,
  annote =       "Software-Quelltexte werden oft durch den Einsatz eines
                 Pr{\"a}prozessors an verschiedenen Zielplattformen
                 angepa{\"s}t. Aus einem Quelltext entstehen dabei durch
                 den Pr{\"a}prozessor verschiedene Varianten der
                 Software, die einen Variantenverband bilden. Formale
                 Begriffsanalyse ist eine mathematische Theorie, mit
                 deren Hilfe der Variantenverband von Quelltexten
                 effizient bestimmt werden kann. Dar{\"u}berhinaus
                 k{\"o}nnen Redundanzen in der Beschreibung der
                 Variantenstruktur entdeckt und entfernt werden.",
}



@InProceedings{AtkinsBGM99,
  author = 	 "David Atkins and Thomas Ball and Todd Graves and Audris Mockus",
  title = 	 "Using Version Control Data to Evaluate the Impact of Software Tools",
  booktitle = 	 icse99,
  OPTpages = 	 "",
  year =	 1999,
  address =	 "Los Angeles, CA",
  month =	 may # "~19-21,"
}
The idea is to evaluate VE, a #if-aware editor that supports changing a
program that makes extensive use of the C preprocessor.  The editor hides
Cpp conditionals that are not active in a particular version of the
software, and it automatically inserts Cpp conditionals around new code
added using the editor.
  The methodology is to find programmers who have made nontrivial numbers
of modifications to the codebase both using and not using the tool and
compare their productivity, measured in time per number of lines of
changes, while controlling for type of change.  This information is found
in the version control logs.  Only 9 out of 5000 programmers fit the
criterion; of these, 8 switched from not using the tool to using it, and
one vice versa.
  They conclude that the tool is effective.


% This might be the right reference for the VE editor.
J. O. Coplien, D. L. DeBruler, and M. B. Thompson
The delta system:  A nontraditional approach to software version management
In International Switching Symposium, March 1987.



% This doesn't look like the right reference for the VE editor.
Version Sensitive Editing: Change History as a Programming Tool 
David L. Atkins
Bell labs - Lucent Technologies, USA 
Lecture Notes in Computer Science 1439, Springer Verlag, Boris Magnusson (Ed.)
     System Configuration Management
     ECOOP'98 SCM-8 Symposium
     Brussels, Belgium, July 1998
Abstract: 
Software Version Control Systems (VCSs) are used to store the versions of
program source code created throughout the software development cycle. The
traditional purpose of such systems has been mostly administrative,
providing the safe storage of source code and the ability to recreate
earlier versions, as well as tracking the progress of new feature
development and problem resolution. Software developers often regard the
VCS as a necessary but unpleasant encumbrance to the software design and
coding process. However, when the change history data gathered by the VCS
is easily available to the programmer in the context of an editor, the
programming process is enhanced. Faults introduced by earlier changes can
be more rapidly located, dependencies on other changes can be avoided, and
the version history provides valuable hindsight that can help to guide
future development.





@Book{Zipf49,
  author =	 "George Kingsley Zipf",
  title = 	 "Human Behavior and the Principle of Least Effort",
  publisher = 	 "Addison-Wesley",
  year = 	 1949,
  address =	 "Cambridge, MA"
}
Zipf's law.


@InProceedings{ICCC::Salomon1996,
  title =        "Using Partial Evaluation in Support of Portability,
                 Reusability, and Maintainability",
  author =       "Daniel J. Salomon",
  booktitle =    "Compiler Construction, 6th International Conference",
  editor =       "Tibor Gyimothy",
  address =      "Link{\"o}ping, Sweden",
  month =        "24--26~" # apr,
  year =         "1996",
  series =       "Lecture Notes in Computer Science",
  volume =       "1060",
  publisher =    "Springer",
  ISBN =         "ISBN 3-540-61053-7",
  pages =        "208--222",
}
As of 2/96, author is salomon at cs.umanitoba.ca
As of 6/98, perhaps salomon at escape.ca; I don't have permission to access
http://www.escape.ca/~salomon
Abstract:
  Partial evaluation is ordinarily intended to be used to increase program
  efficiency. This paper shows how partial evaluation can be used in place of
  a preprocessor phase and of source-code templates (e.g. C++ templates or
  Ada generics). In this way it can be used to support portability features
  provided by a preprocessor, and the reusability provided by code templates,
  but with higher maintainability due to the simpler syntax required. The
  important mechanisms needed are: annotating variables and functions with an
  evaluation time, treating declarations as translation-time "executable"
  statements, treating user-defined types as translation-time variables,
  giving programmers control over the scope of symbols, and providing
  translation-time name binding. The effects of these changes on the size and
  complexity of a compiler are estimated. A translator for a language called
  "Safer-C" which supports these techniques has been implemented. Important
  existing C software is analyzed to evaluate the applicability of these
  techniques in replacing the preprocessor.



@InBook{DavisDL90,
  author =	 "J.S. Davis and M.J. Davis and M.M. Law",
  title = 	 "Empirical Foundations of Information and Software Science",
  chapter = 	 "Comparison of subjective entropy and user estimates of software complexity",
  publisher = 	 "V. Plenum",
  year = 	 1990,
  address =	 "New York, NY, USA"
}
Abstract:
  The authors investigated subjective entropy, a new information-theoretic
  measure of program comprehensibility which accounts for semantics and
  pragmatics involved in programmer-program interaction. Student subjects
  were administered subjective entropy tests on program samples in dBase
  III and Lotus 1-2-3 macro languages. Since the test employed an automated
  tool and required an average of only 20 minutes, they found it practical
  to administer. Subjective entropy scores indicated that the program in
  Lotus 1-2-3 macro language was more difficult to understand. The scores
  were consistent with expert opinion and with the subjective ratings of
  the subjects.


@Misc{Lott-metrics-tools,
  author =	 "Christopher Lott",
  title =	 "Metrics collection tools for C and C++ Source Code",
  howpublished = "http://www.cs.umd.edu/users/cml/cmetrics/",
  year =	 1998
}
I know the year is at least 1998 because one of the packages says "last
updated in 1998".  Most of the packages are quite a bit older, though.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% I haven't yet read the following articles.
%%%

@InProceedings{favre:97,
  author =       "Jean-Marie Favre",
  title =        "{CPP} Denotational Semantics and its Application to
                 Software Maintenance",
  booktitle =    "1st Euromicro Working Conference on Software
                 Maintenance and Reengineering CSMR 97",
  month =        mar,
  year =         "1997",
  publisher =    "IEEE Computer Society Press",
  abstract =     "Very often, portability of large software products is
                 achieved via the empirical use of old tools like CPP,
                 the preprocessor of the C language. Though powerful low
                 level features like conditional compilation cause
                 serious maintenance problems. There is a lack of
                 adequate tools to support such activities. This paper
                 presents our approach to this problem. We introduce
                 APP, an abstract language semantically equivalent to
                 CPP but based on traditional programming-in-the-small
                 concepts. A rigorous description of the semantics of
                 this language makes it possible to develop reliable
                 reverse engineering tools.",
  class =        "Reverse_Engineering, Reverse_Design,
                 Configuration_Structures",
  sender =       "antonio@ifi.unizh.ch",
}


Other Favre papers in English (from
http://www-adele.imag.fr/users/Jean-Marie.Favre/):

     J.M. Favre 
     "Understanding-In-The-Large" 
     International Workshop on Program Comprehension (IWPC'97) 
     Deadborn (Michigan), May 
     1997 

     J.M. Favre 
     "A Rigorous Approach to Support the Maintenance of Large Portable Software 
     Euromicro Working Conference on Software Maintenance and Reengineering (CSMR'97) 
     Berlin (Germany), March 
     1997 

     J.M. Favre 
     "Using Mathematical abstractions to support reverse engineering of software variant representations" 
     4th International Symposium on Applied Corporate Computing (ISACC'96) 
     Monterrey (Mexico), November 
     1996 

     J.M. Favre 
     "Reverse Engineering and Configuration Management: Concepts and Perspectives" 
     Software Conf'96 
     Paris (France), 11-12 June, 6 pages 
     1996 

     J.M. Favre 
     "Support For Reengineering-in-The-Large" 
     Doctoral Consortium of CAiSE'94 
     (Workshop of the 6th International Conference of Computer Aided Information System Engineering, Utrecht (Netherlands), 6-10 june,
     1994), 
     Memoranda Informatica 94-24, Univeristy of Twente 
     1994. 

     J.M. Favre 
     "Reengineering-in-The-Large vs Reengineering-in-The-Small" 
     1st SEI Workshop on Reengineering, 
     Pittsburgh, 3-5 may 1994, Software Engineering Institute, Carnegie Mellon University 
     1994. 

     J. Estublier and J.M. Favre 
     "Structuring Large Versioned Software Products" 
     13th International Computer Software and Applications Conference, 
     Orlando (Florida), September, pp. 404-411, 
     1989. 




@InProceedings{LivadasS94,
  author = 	 "Panos E. Livadas and David T. Small",
  title = 	 "Understanding code containing preprocessor constructs",
  booktitle = 	 "IEEE Third Workshop on Program Comprehension",
  year =	 1994,
  address =	 "Washington, DC, USA",
  month =	 nov # "~14-15",
  pages =	 "89-97"
}
Understanding Code Containing Preprocessor constructs, by Panos E. Livadas and David T. Small, SERC-TR-73-F, June 1994.
Description: Understanding, debugging, and maintaining software is a costly
and difficult task. The difficulties are exacerbated in programs written to
take advantage of preprocessing facilities. This paper examines problems
associated with source code containing preprocessor constructs -i.e.,
included files, conditional compilation, and macros. We define the useful
mappings from tokens in the proprocessor's output to the source file(s),
and propose that by capturing these correspondences an internal program
representation can be built which will allow for the use of maintenance
techniques including program slicing, dicing, and ripple analysis. The
method presented is generic; to illustrate that the technique is feasible,
we discuss ANSI C preprocessor constructs - in particular, macro
substitution - and explain the modules developed to handle them in Ghinsu -
an integrated maintenance environment for ANSI C programs.
Accession No.: 4847215.
Author:        Livadas-P-E.  Small-D-T.
Author Affil.: Dept. of Comput. & Inf. Sci., Florida Univ., Gainesville, FL,
               USA.
Title:         Understanding code containing preprocessor constructs.
Source:        Published by: IEEE Comput. Soc. Press.  Los Alamitos, CA, USA. 
               1994.
References:    12 refs.
Conf. Title:   Proceedings. IEEE Third Workshop on Program Comprehension (Cat.
               No.94TH06767).  Washington, DC, USA.  pp. 89-97.  IEEE Comput. 
               Soc. Tech. Council on Software Eng.  14-15 Nov. 1994.
ISBN:          0818656476.
Language:      eng.
Year:          1994.
Pub. Type:     conference-proceeding (C).
Treatment:     PRACTICAL OR PRODUCT REVIEW (P).
Report No.:    CCCC: 0 8186 5647 6/94/$04.00.
Pub. Country:  USA.
Class. Code:   C6110.  C6115.  C6150G.
Subject:       macros.  program-debugging.  programming-environments. reverse-
               engineering.  software-maintenance.
Identifiers:   code understanding.  preprocessor constructs.  debugging. 
               software maintenance.  included files.  conditional
               compilation.  macro substitution.  tokens.  source file. 
               internal program representation. program slicing.  ripple
               analysis.  dicing.  ANSI C preprocessor constructs. 
               GHINSU.  integrated maintenance environment.
Abstract:      Understanding, debugging, and maintaining software is a costly
               and difficult task.  The difficulties are exacerbated in
               programs written to take advantage of preprocessing facilities.
                This paper examines problems associated with source code
               containing preprocessor constructs-i.e. included files,
               conditional compilation and macros.  We define the useful
               mappings from tokens in the preprocessor's output to the source
               file(s), and propose that by capturing these correspondences,
               an internal program representation can be built which allows
               for the use of maintenance techniques including program
               slicing, ripple analysis and dicing.  The method presented is
               generic;  to illustrate that the technique is feasible, we
               discuss ANSI C preprocessor constructs-in particular,
               macro substitution-and explain the modus developed to handle
               them in GHINSU-an integrated maintenance environment for ANSI C
               programs.
UW Load Date   9501.
Holdings:      Local holdings could not be determined. Consult UW catalogs.

@Article{ABACUS89,
  key =          "Abacus",
  author =       "A. Abacus",
  title =        "Parameterizing {C} Code at Compile and Run Time",
  journal =      "Structured Programming",
  publisher =    "Springer-Verlag",
  volume =       "10",
  number =       "4",
  year =         "1989",
  pages =        "209--214",
  keywords =     "parameterization; C; debugging; imbedded debugging
                 code; C preprocessor",
  abstract =     "This paper describes a convenient mechanism for
                 imbedding debugging code within the source code of
                 programs written in C. Debugging code can be packaged
                 into any number of functionally independent debugging
                 units. Conditional compilation of each unit is
                 controlled by a separate compile time switch. Execution
                 of each compiled unit is controlled by a separate run
                 time switch. Efficient final products can be generated
                 by turning off compile time switches of all debugging
                 units. This packaging method depends on the C
                 preprocessor and its final refinement depends on the
                 ability of the compiler to perform 'dead code removal'
                 optimization. Each routine or a family of related
                 routines can be parameterized independently of other
                 routines. Run time options of library routines can be
                 changed without access to their source code. This
                 parameterization is not restricted to debugging code.
                 The same mechanism may be used to select one of several
                 implementations of a feature, or to set initial values
                 of variables.",
  bibdate =      "Tue Nov 7 08:25:39 1989",
  owner =        "robyn",
}

@Article{Mudd:1990:ACD,
  author =       "John Mudd",
  title =        "Automating {C} Debugging with Preprocessor Macros",
  journal =      "Computer Language Magazine",
  volume =       "7",
  number =       "2",
  pages =        "69--??",
  month =        feb,
  year =         "1990",
  coden =        "COMLEF",
  ISSN =         "0749-2839",
  bibdate =      "Tue Jan 23 08:04:25 MST 1996",
  acknowledgement = ack-nhfb,
}

@Article{Allison:1994:P,
  author =       "Chuck Allison",
  title =        "The Preprocessor",
  journal =      "C Users Journal",
  volume =       "12",
  type =         "Code Capsules",
  number =       "3",
  pages =        "101--??",
  month =        mar,
  year =         "1994",
  ISSN =         "0898-9788",
  bibdate =      "Fri Aug 30 16:52:23 MDT 1996",
  acknowledgement = ack-nhfb,
}

%% These resulted from an online search for "Cpp"

@Article{Parks:JCLT-2-3-194,
  author =       "John H. Parks",
  title =        "Case Study: Building an {ANSI CPP}",
  journal =      "The Journal of {C} Language Translation",
  volume =       "2",
  number =       "3",
  pages =        "194--206",
  month =        dec,
  year =         "1990",
  ISSN =         "1042-5721",
  bibdate =      "Fri Nov 21 15:06:25 1997",
  acknowledgement = ack-nhfb,
  remark =       "A thorough look at the issues involved in building an
                 ideal preprocessor that can be user-configurable to
                 support ANSI C and most common extensions.",
}


@Article{Hazard:1991:UCA,
  author =       "William P. Hazard",
  title =        "Using cpp to Aid Portability",
  journal =      "Computer Language Magazine",
  volume =       "8",
  number =       "11",
  pages =        "49--??",
  month =        nov,
  year =         "1991",
  coden =        "COMLEF",
  ISSN =         "0749-2839",
  bibdate =      "Tue Jan 23 08:04:25 MST 1996",
  acknowledgement = ack-nhfb,
}

@InProceedings{Locanthi:1987:FBA,
  author =       "Bart N. Locanthi",
  title =        "Fast bitblt() with asm() and cpp",
  editor =       "{USENIX Association}",
  booktitle =    "{EUUG} Conference Proceedings, Autumn, 1987. Dublin,
                 Ireland",
  publisher =    "EUUG",
  address =      "Buntingford, Herts, UK",
  month =        "Autumn",
  year =         "1987",
  pages =        "243--259",
  month =        "Autumn",
  year =         "1987",
  bibdate =      "Tue Feb 20 15:42:13 MST 1996",
  acknowledgement = ack-nhfb,
  affiliation =  "AT\&T Bell Laboratories, Murray Hill",
}

@Article{Ream:1990:CCV,
  author =       "Edward K. Ream",
  title =        "{CUG319 CPP v5.3}",
  journal =      "C Users Journal",
  volume =       "8",
  type =         "CUG New Release",
  number =       "7",
  pages =        "111--??",
  month =        jul,
  year =         "1990",
  ISSN =         "0898-9788",
  bibdate =      "Fri Aug 30 16:52:23 MDT 1996",
  acknowledgement = ack-nhfb,
}


Accession No.: 3813929.
Author:        Sumerlin-W.
Author Affil.: MMC AD Syst., Milpitas, CA, USA.
Title:         Writing an ANSI C preprocessor.
Source:        Programmer's Journal.  vol.8, no.6.  pp. 58, 60-2.  Nov.-Dec. 
               1990.
ISSN:          0747-5861.
CODEN:         PRGJE7.
Language:      eng.
Year:          1990.
Pub. Type:     journal-article (J).
Treatment:     PRACTICAL OR PRODUCT REVIEW (P).
Pub. Country:  USA.
Class. Code:   C6140D.  C6150C.
Subject:       C-language.  C-listings.  program-processors.  standards.
Identifiers:   ANSI C. preprocessor.  ANSI standard.
Abstract:      Considers implementation problems in complying with the new
               ANSI C standards.  With the new ANSI C standard, there are new
               operators, new preprocessing commands, and new specific size
               limits.  As a result, the preprocessor has to be sensitive to
               when it can and cannot expand macro definitions.  Due to the
               new requirements, small design and implementation changes in
               the preprocessor can have dramatic effects on whether the
               preprocessor meets or misses the ANSI C standard.  The ANSI
               standard is described in two documents.  The first provides
               rules and examples, while the second describes why some things
               were done the way they were.
Holdings:      Engineering Periodicals
                 SHELVED BY TITLE: Programmer's journal
                 CALL NUMBER: QA76.8.I2594 P7557
                 LIB HAS: v.1-9 no.5 (1983-Sept./Dec. 1991)  Incomplete

